# å¼€å‘æ–‡æ¡£ï¼šå¼‚æ­¥å·¥ä½œæµå’Œæ¶ˆæ¯é˜Ÿåˆ—é›†æˆå®ç°

> **æ–‡æ¡£çŠ¶æ€**: å¼€å‘è®¡åˆ’  
> **ä¼˜å…ˆçº§**: P0 - æœ€é«˜ä¼˜å…ˆçº§  
> **é¢„ä¼°å·¥ä½œé‡**: 3-5å¤©  
> **æ›´æ–°æ—¥æœŸ**: 2024-08-20  

## 1. å¼€å‘ç›®æ ‡

å°†å½“å‰çš„åŒæ­¥AIä»£ç ç”Ÿæˆæ”¹é€ ä¸ºå®Œæ•´çš„å¼‚æ­¥æ˜ä¿¡ç‰‡ç”Ÿæˆå·¥ä½œæµï¼Œå®ç°ï¼š

1. **æ¶ˆæ¯é˜Ÿåˆ—é›†æˆ** - ä½¿ç”¨Redis Streamså®ç°å¼‚æ­¥ä»»åŠ¡å¤„ç†
2. **å¤šæ­¥éª¤AIå·¥ä½œæµ** - æ¦‚å¿µâ†’æ–‡æ¡ˆâ†’å›¾ç‰‡â†’å‰ç«¯ä»£ç çš„å®Œæ•´æµæ°´çº¿  
3. **ä»»åŠ¡çŠ¶æ€ç®¡ç†** - å®ç°å¯è¿½è¸ªçš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ
4. **ç³»ç»Ÿè§£è€¦** - APIç½‘å…³ã€æ˜ä¿¡ç‰‡æœåŠ¡ã€AI AgentæœåŠ¡çš„å¼‚æ­¥åä½œ

## 2. å½“å‰å®ç°åˆ†æ

### 2.1. ç°æœ‰åŠŸèƒ½
âœ… **AI Agent Service** (`src/ai-agent-service/`)ï¼š
- Claude Code SDKé›†æˆå®Œæˆ
- å‰ç«¯ä»£ç ç”Ÿæˆèƒ½åŠ›å®Œæ•´
- Vue.jså‰ç«¯ç•Œé¢ï¼ˆLovart.aiæ¨¡æ‹Ÿå™¨ï¼‰
- WebSocketå®æ—¶é€šä¿¡

### 2.2. éœ€è¦æ”¹é€ çš„éƒ¨åˆ†
ğŸ”„ **åŒæ­¥â†’å¼‚æ­¥è½¬æ¢**ï¼š
- å½“å‰é€šè¿‡HTTPç›´æ¥è°ƒç”¨AIç”Ÿæˆ
- éœ€è¦æ”¹ä¸ºæ¶ˆæ¯é˜Ÿåˆ—å¼‚æ­¥å¤„ç†æ¨¡å¼

ğŸ†• **ç¼ºå¤±çš„æœåŠ¡**ï¼š
- æ˜ä¿¡ç‰‡æœåŠ¡ï¼ˆä»»åŠ¡çŠ¶æ€ç®¡ç†ï¼‰
- æ¶ˆæ¯é˜Ÿåˆ—åŸºç¡€è®¾æ–½
- å¤šæ­¥éª¤å·¥ä½œæµç¼–æ’å™¨

## 3. æŠ€æœ¯æ¶æ„è®¾è®¡

### 3.1. æ•´ä½“å¼‚æ­¥æµç¨‹

```mermaid
sequenceDiagram
    participant Client as "å‰ç«¯/å°ç¨‹åº"
    participant Gateway as "APIç½‘å…³"
    participant PostcardSvc as "æ˜ä¿¡ç‰‡æœåŠ¡"
    participant Queue as "æ¶ˆæ¯é˜Ÿåˆ—(Redis)"
    participant Agent as "AI AgentæœåŠ¡"

    Client->>+Gateway: "POST /postcards/create"
    Gateway->>+PostcardSvc: "åˆ›å»ºæ˜ä¿¡ç‰‡ä»»åŠ¡"
    PostcardSvc->>PostcardSvc: "ç”Ÿæˆtask_idï¼ŒçŠ¶æ€=PENDING"
    PostcardSvc->>+Queue: "å‘å¸ƒä»»åŠ¡æ¶ˆæ¯"
    PostcardSvc-->>-Gateway: "è¿”å›task_id"
    Gateway-->>-Client: "ç«‹å³å“åº”task_id"
    
    Queue->>+Agent: "æ¶ˆè´¹ä»»åŠ¡æ¶ˆæ¯"
    Agent->>+PostcardSvc: "æ›´æ–°çŠ¶æ€=PROCESSING"
    
    loop "AIå·¥ä½œæµæ‰§è¡Œ"
        Agent->>Agent: "1. æ¦‚å¿µç”Ÿæˆ"
        Agent->>Agent: "2. æ–‡æ¡ˆç”Ÿæˆ"
        Agent->>Agent: "3. å›¾ç‰‡ç”Ÿæˆ"
        Agent->>Agent: "4. å‰ç«¯ä»£ç ç”Ÿæˆ"
    end
    
    Agent->>+PostcardSvc: "ä¿å­˜æœ€ç»ˆç»“æœï¼ŒçŠ¶æ€=COMPLETED"
    Agent-->>-Queue: "ç¡®è®¤ä»»åŠ¡å®Œæˆ"
    
    Client->>+Gateway: "GET /postcards/status/task_id"
    Gateway->>+PostcardSvc: "æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"
    PostcardSvc-->>-Gateway: "è¿”å›ç»“æœæ•°æ®"
    Gateway-->>-Client: "çŠ¶æ€å’Œç»“æœ"
```

### 3.2. æœåŠ¡æ¨¡å—è®¾è®¡

#### 3.2.1. æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆRedis Streamsï¼‰
```yaml
# docker-compose.yml æ–°å¢æœåŠ¡
redis:
  image: redis:7-alpine
  ports:
    - "6379:6379"
  command: redis-server --appendonly yes
  volumes:
    - redis_data:/data
```

#### 3.2.2. AI Agent Service é‡æ„

**æ ¸å¿ƒæ¨¡å—ç»“æ„**ï¼š
```
src/ai-agent-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ worker.py                  # æ–°å¢ï¼šå¼‚æ­¥ä»»åŠ¡æ¶ˆè´¹è€…
â”‚   â”œâ”€â”€ orchestrator/              # æ–°å¢ï¼šå·¥ä½œæµç¼–æ’å™¨
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ workflow.py            # å¤šæ­¥éª¤AIå·¥ä½œæµ
â”‚   â”‚   â””â”€â”€ steps/                 # å·¥ä½œæµæ­¥éª¤
â”‚   â”‚       â”œâ”€â”€ concept_generator.py   # æ¦‚å¿µç”Ÿæˆï¼ˆGeminiæ–‡æœ¬ï¼‰
â”‚   â”‚       â”œâ”€â”€ content_generator.py   # å†…å®¹ç”Ÿæˆï¼ˆGeminiæ–‡æœ¬ï¼‰
â”‚   â”‚       â”œâ”€â”€ image_generator.py     # å›¾ç‰‡ç”Ÿæˆï¼ˆGeminiå›¾ç‰‡ï¼‰
â”‚   â”‚       â””â”€â”€ frontend_coder.py      # å‰ç«¯ç¼–ç ï¼ˆClaude Code SDKï¼‰
â”‚   â”œâ”€â”€ providers/                 # æ–°å¢ï¼šAIæœåŠ¡æä¾›å•†é›†æˆ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_provider.py           # æä¾›å•†åŸºç±»
â”‚   â”‚   â”œâ”€â”€ gemini_text_provider.py    # Geminiæ–‡æœ¬ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ gemini_image_provider.py   # Geminiå›¾ç‰‡ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ claude_provider.py         # Claudeä»£ç ç”Ÿæˆï¼ˆç°æœ‰ï¼‰
â”‚   â”‚   â””â”€â”€ provider_factory.py        # æä¾›å•†å·¥å‚
â”‚   â”œâ”€â”€ queue/                     # æ–°å¢ï¼šæ¶ˆæ¯é˜Ÿåˆ—é›†æˆ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ consumer.py            # ä»»åŠ¡æ¶ˆè´¹è€…
â”‚   â”‚   â”œâ”€â”€ producer.py            # ä»»åŠ¡ç”Ÿäº§è€…
â”‚   â”‚   â””â”€â”€ models.py              # ä»»åŠ¡æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ utils/                     # æ–°å¢ï¼šå·¥å…·æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ image_utils.py         # å›¾ç‰‡å¤„ç†å·¥å…·
â”‚   â”‚   â”œâ”€â”€ text_utils.py          # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â”‚   â””â”€â”€ validation.py          # æ•°æ®éªŒè¯å·¥å…·
â”‚   â””â”€â”€ coding_service/            # ç°æœ‰ï¼šä¿ç•™ï¼Œä½œä¸ºå·¥ä½œæµçš„æœ€åä¸€æ­¥
```

**3.2.2.1. Gemini Provider å®ç°**

**Gemini æ–‡æœ¬ç”ŸæˆProvider**ï¼š
```python
# src/ai-agent-service/app/providers/gemini_text_provider.py
import google.generativeai as genai
from typing import Dict, Any, Optional
from .base_provider import BaseProvider
import os

class GeminiTextProvider(BaseProvider):
    """Geminiæ–‡æœ¬ç”ŸæˆæœåŠ¡æä¾›å•†"""
    
    def __init__(self):
        # é…ç½®Gemini API
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEYç¯å¢ƒå˜é‡æœªé…ç½®")
            
        genai.configure(api_key=api_key)
        
        # é…ç½®æ¨¡å‹å‚æ•°
        self.model_name = os.getenv("GEMINI_TEXT_MODEL", "gemini-1.5-flash")
        self.default_config = {
            "temperature": float(os.getenv("GEMINI_TEXT_TEMPERATURE", "0.7")),
            "max_output_tokens": int(os.getenv("GEMINI_TEXT_MAX_TOKENS", "2048")),
            "top_p": 0.8,
            "top_k": 40
        }
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config=genai.GenerationConfig(**self.default_config)
        )
    
    async def generate_text(
        self, 
        prompt: str, 
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        **kwargs
    ) -> str:
        """ç”Ÿæˆæ–‡æœ¬å†…å®¹"""
        try:
            # åŠ¨æ€é…ç½®ç”Ÿæˆå‚æ•°
            config = self.default_config.copy()
            if max_tokens:
                config["max_output_tokens"] = max_tokens
            if temperature is not None:
                config["temperature"] = temperature
            
            # é‡æ–°é…ç½®æ¨¡å‹
            model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=genai.GenerationConfig(**config)
            )
            
            # ç”Ÿæˆå†…å®¹
            response = await model.generate_content_async(prompt)
            
            if response.parts:
                return response.text
            else:
                raise Exception("Geminiè¿”å›ç©ºå“åº”")
                
        except Exception as e:
            self.logger.error(f"Geminiæ–‡æœ¬ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            test_response = await self.generate_text("æµ‹è¯•è¿æ¥", max_tokens=10)
            return bool(test_response)
        except:
            return False
```

**Gemini å›¾ç‰‡ç”ŸæˆProvider**ï¼š
```python
# src/ai-agent-service/app/providers/gemini_image_provider.py
import google.generativeai as genai
from typing import Dict, Any, Optional
from .base_provider import BaseProvider
import os
import aiohttp
import base64

class GeminiImageProvider(BaseProvider):
    """Geminiå›¾ç‰‡ç”ŸæˆæœåŠ¡æä¾›å•†"""
    
    def __init__(self):
        # é…ç½®API
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEYç¯å¢ƒå˜é‡æœªé…ç½®")
            
        self.api_key = api_key
        self.base_url = os.getenv("GEMINI_BASE_URL", "https://generativelanguage.googleapis.com")
        self.model_name = os.getenv("GEMINI_IMAGE_MODEL", "imagen-3.0-generate-001")
        self.default_size = os.getenv("GEMINI_IMAGE_SIZE", "1024x1024")
        self.default_quality = os.getenv("GEMINI_IMAGE_QUALITY", "standard")
    
    async def generate_image(
        self,
        prompt: str,
        size: Optional[str] = None,
        quality: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾ç‰‡"""
        try:
            size = size or self.default_size
            quality = quality or self.default_quality
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            request_data = {
                "prompt": prompt,
                "size": size,
                "quality": quality,
                "response_format": "url"  # æˆ– "b64_json"
            }
            
            # å‘é€è¯·æ±‚åˆ°Geminiå›¾ç‰‡ç”ŸæˆAPI
            async with aiohttp.ClientSession() as session:
                url = f"{self.base_url}/v1/models/{self.model_name}:generateImage"
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                async with session.post(url, json=request_data, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        
                        return {
                            "image_url": result.get("image_url"),
                            "metadata": {
                                "prompt": prompt,
                                "size": size,
                                "quality": quality,
                                "model": self.model_name
                            }
                        }
                    else:
                        error_msg = f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {response.status} - {await response.text()}"
                        self.logger.error(error_msg)
                        raise Exception(error_msg)
                        
        except Exception as e:
            self.logger.error(f"Geminiå›¾ç‰‡ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            # ç®€å•çš„è¿æ¥æµ‹è¯•
            async with aiohttp.ClientSession() as session:
                url = f"{self.base_url}/v1/models"
                headers = {"Authorization": f"Bearer {self.api_key}"}
                async with session.get(url, headers=headers) as response:
                    return response.status == 200
        except:
            return False
```

**Providerå·¥å‚æ¨¡å¼**ï¼š
```python
# src/ai-agent-service/app/providers/provider_factory.py
from typing import Dict, Type, Any
from .base_provider import BaseProvider
from .gemini_text_provider import GeminiTextProvider
from .gemini_image_provider import GeminiImageProvider
from .claude_provider import ClaudeProvider

class ProviderFactory:
    """AIæœåŠ¡æä¾›å•†å·¥å‚"""
    
    _text_providers: Dict[str, Type[BaseProvider]] = {
        "gemini": GeminiTextProvider,
        "claude": ClaudeProvider  # å¦‚éœ€è¦æ–‡æœ¬ç”Ÿæˆ
    }
    
    _image_providers: Dict[str, Type[BaseProvider]] = {
        "gemini": GeminiImageProvider,
        # "dalle": DalleProvider,  # æœªæ¥æ‰©å±•
    }
    
    _code_providers: Dict[str, Type[BaseProvider]] = {
        "claude": ClaudeProvider,
    }
    
    @classmethod
    def create_text_provider(cls, provider_type: str = "gemini") -> BaseProvider:
        """åˆ›å»ºæ–‡æœ¬ç”Ÿæˆæä¾›å•†"""
        if provider_type not in cls._text_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡æœ¬æä¾›å•†: {provider_type}")
        return cls._text_providers[provider_type]()
    
    @classmethod
    def create_image_provider(cls, provider_type: str = "gemini") -> BaseProvider:
        """åˆ›å»ºå›¾ç‰‡ç”Ÿæˆæä¾›å•†"""
        if provider_type not in cls._image_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„å›¾ç‰‡æä¾›å•†: {provider_type}")
        return cls._image_providers[provider_type]()
    
    @classmethod
    def create_code_provider(cls, provider_type: str = "claude") -> BaseProvider:
        """åˆ›å»ºä»£ç ç”Ÿæˆæä¾›å•†"""
        if provider_type not in cls._code_providers:
            raise ValueError(f"ä¸æ”¯æŒçš„ä»£ç æä¾›å•†: {provider_type}")
        return cls._code_providers[provider_type]()
```

#### 3.2.3. æ˜ä¿¡ç‰‡æœåŠ¡ï¼ˆæ–°å»ºï¼‰
```
src/postcard-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨
â”‚   â”œâ”€â”€ models/                    # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postcard.py            # æ˜ä¿¡ç‰‡æ¨¡å‹
â”‚   â”‚   â””â”€â”€ task.py                # ä»»åŠ¡æ¨¡å‹
â”‚   â”œâ”€â”€ api/                       # APIè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postcards.py           # æ˜ä¿¡ç‰‡CRUD
â”‚   â”‚   â””â”€â”€ tasks.py               # ä»»åŠ¡çŠ¶æ€ç®¡ç†
â”‚   â”œâ”€â”€ services/                  # ä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postcard_service.py
â”‚   â”‚   â””â”€â”€ task_service.py
â”‚   â””â”€â”€ database/                  # æ•°æ®åº“é›†æˆ
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ connection.py
â”‚       â””â”€â”€ migrations/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile.dev
â””â”€â”€ tests/
```

## 4. å®ç°è®¡åˆ’

### 4.1. Phase 1: åŸºç¡€è®¾æ–½æ­å»ºï¼ˆ1å¤©ï¼‰

**4.1.1. Redisé›†æˆ**
```bash
# 1. æ›´æ–°docker-compose.ymlæ·»åŠ RedisæœåŠ¡
# 2. æ›´æ–°ç¯å¢ƒå˜é‡é…ç½®
# 3. æµ‹è¯•Redisè¿æ¥
```

**4.1.2. æ˜ä¿¡ç‰‡æœåŠ¡éª¨æ¶**
```bash
# 1. åˆ›å»ºsrc/postcard-serviceç›®å½•ç»“æ„
# 2. å®ç°åŸºç¡€çš„FastAPIåº”ç”¨
# 3. æ·»åŠ åˆ°docker-compose.yml
# 4. å®ç°å¥åº·æ£€æŸ¥æ¥å£
```

### 4.2. Phase 2: æ¶ˆæ¯é˜Ÿåˆ—é›†æˆï¼ˆ1-2å¤©ï¼‰

**4.2.1. ä»»åŠ¡æ•°æ®æ¨¡å‹è®¾è®¡**
```python
# src/ai-agent-service/app/queue/models.py
from pydantic import BaseModel
from typing import Dict, Any, Optional
from enum import Enum

class TaskType(str, Enum):
    POSTCARD_GENERATION = "postcard_generation"

class TaskStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing" 
    COMPLETED = "completed"
    FAILED = "failed"

class PostcardGenerationTask(BaseModel):
    task_id: str
    task_type: TaskType = TaskType.POSTCARD_GENERATION
    user_input: str              # ç”¨æˆ·è¾“å…¥çš„åˆ›ä½œè¦æ±‚
    style: Optional[str] = None  # é£æ ¼é€‰æ‹©
    theme: Optional[str] = None  # ä¸»é¢˜é€‰æ‹©
    created_at: str
    metadata: Dict[str, Any] = {}
```

**4.2.2. æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹è€…å®ç°**
```python
# src/ai-agent-service/app/queue/consumer.py
import asyncio
import redis.asyncio as redis
from ..orchestrator.workflow import PostcardWorkflow

class TaskConsumer:
    def __init__(self):
        self.redis = redis.Redis(host="redis", port=6379)
        self.workflow = PostcardWorkflow()
    
    async def start_consuming(self):
        """å¼€å§‹æ¶ˆè´¹ä»»åŠ¡"""
        while True:
            try:
                messages = await self.redis.xread({
                    "postcard_tasks": "$"
                }, block=1000)
                
                for stream, msgs in messages:
                    for msg_id, fields in msgs:
                        await self.process_task(fields)
            except Exception as e:
                logger.error(f"æ¶ˆè´¹ä»»åŠ¡å¤±è´¥: {e}")
                await asyncio.sleep(5)
    
    async def process_task(self, task_data):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task = PostcardGenerationTask(**task_data)
        await self.workflow.execute(task)
```

### 4.3. Phase 3: å¤šæ­¥éª¤å·¥ä½œæµå®ç°ï¼ˆ2å¤©ï¼‰

**4.3.1. å·¥ä½œæµç¼–æ’å™¨**
```python
# src/ai-agent-service/app/orchestrator/workflow.py
from ..queue.models import PostcardGenerationTask
from .steps import ConceptGenerator, ContentGenerator, ImageGenerator, FrontendCoder

class PostcardWorkflow:
    def __init__(self):
        self.steps = [
            ConceptGenerator(),    # ç¬¬1æ­¥ï¼šæ¦‚å¿µç”Ÿæˆ
            ContentGenerator(),    # ç¬¬2æ­¥ï¼šæ–‡æ¡ˆç”Ÿæˆ  
            ImageGenerator(),      # ç¬¬3æ­¥ï¼šå›¾ç‰‡ç”Ÿæˆ
            FrontendCoder()        # ç¬¬4æ­¥ï¼šå‰ç«¯ç¼–ç ï¼ˆå¤ç”¨ç°æœ‰èƒ½åŠ›ï¼‰
        ]
    
    async def execute(self, task: PostcardGenerationTask):
        """æ‰§è¡Œå®Œæ•´çš„æ˜ä¿¡ç‰‡ç”Ÿæˆå·¥ä½œæµ"""
        context = {"task": task, "results": {}}
        
        try:
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
            await self.update_task_status(task.task_id, "PROCESSING")
            
            # ä¾æ¬¡æ‰§è¡Œå„ä¸ªæ­¥éª¤
            for step in self.steps:
                logger.info(f"æ‰§è¡Œæ­¥éª¤: {step.__class__.__name__}")
                context = await step.execute(context)
                
                # ä¿å­˜ä¸­é—´ç»“æœ
                await self.save_intermediate_result(task.task_id, step.__class__.__name__, context["results"])
            
            # ä¿å­˜æœ€ç»ˆç»“æœ
            await self.save_final_result(task.task_id, context["results"])
            await self.update_task_status(task.task_id, "COMPLETED")
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            await self.update_task_status(task.task_id, "FAILED", str(e))
```

**4.3.2. å„æ­¥éª¤å®ç°**

**4.3.2.1. æ¦‚å¿µç”Ÿæˆå™¨ï¼ˆGeminiæ–‡æœ¬ç”Ÿæˆï¼‰**
```python
# src/ai-agent-service/app/orchestrator/steps/concept_generator.py
import google.generativeai as genai
from ..providers.gemini_provider import GeminiTextProvider

class ConceptGenerator:
    def __init__(self):
        self.gemini_provider = GeminiTextProvider()
    
    async def execute(self, context):
        """ç”Ÿæˆæ˜ä¿¡ç‰‡æ¦‚å¿µå’Œåˆ›æ„æ–¹å‘"""
        task = context["task"]
        
        # æ„å»ºæ¦‚å¿µç”Ÿæˆæç¤ºè¯
        concept_prompt = f"""
        æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆæ˜ä¿¡ç‰‡åˆ›æ„æ¦‚å¿µï¼š{task.user_input}
        
        è¯·ç”Ÿæˆï¼š
        1. ä¸»é¢˜æ¦‚å¿µï¼šæ˜ä¿¡ç‰‡çš„æ ¸å¿ƒä¸»é¢˜å’Œæƒ…æ„Ÿè¡¨è¾¾
        2. è§†è§‰é£æ ¼ï¼šè‰²å½©ã€æ„å›¾ã€è‰ºæœ¯é£æ ¼å»ºè®®
        3. æ–‡æ¡ˆæ–¹å‘ï¼šæ–‡å­—å†…å®¹çš„æƒ…æ„ŸåŸºè°ƒå’Œè¡¨è¾¾æ–¹å¼
        4. ç›®æ ‡å—ä¼—ï¼šé€‚åˆçš„ä½¿ç”¨åœºæ™¯å’Œäººç¾¤
        
        ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
        """
        
        # è°ƒç”¨Geminiæ–‡æœ¬ç”Ÿæˆ
        concept = await self.gemini_provider.generate_text(
            prompt=concept_prompt,
            max_tokens=1024,
            temperature=0.8
        )
        
        context["results"]["concept"] = concept
        return context
```

**4.3.2.2. å†…å®¹ç”Ÿæˆå™¨ï¼ˆGeminiæ–‡æœ¬ç”Ÿæˆï¼‰**
```python
# src/ai-agent-service/app/orchestrator/steps/content_generator.py
class ContentGenerator:
    def __init__(self):
        self.gemini_provider = GeminiTextProvider()
    
    async def execute(self, context):
        """åŸºäºæ¦‚å¿µç”Ÿæˆæ˜ä¿¡ç‰‡æ–‡æ¡ˆå†…å®¹"""
        task = context["task"]
        concept = context["results"]["concept"]
        
        content_prompt = f"""
        åŸºäºä»¥ä¸‹æ¦‚å¿µç”Ÿæˆæ˜ä¿¡ç‰‡æ–‡æ¡ˆï¼š
        
        æ¦‚å¿µä¿¡æ¯ï¼š{concept}
        ç”¨æˆ·éœ€æ±‚ï¼š{task.user_input}
        
        è¯·ç”Ÿæˆï¼š
        1. ä¸»æ ‡é¢˜ï¼šç®€æ´æœ‰åŠ›çš„ä¸»è¦æ–‡å­—
        2. å‰¯æ ‡é¢˜ï¼šè¡¥å……è¯´æ˜æˆ–æƒ…æ„Ÿè¡¨è¾¾
        3. æ­£æ–‡å†…å®¹ï¼šè¯¦ç»†çš„ç¥ç¦æˆ–è¡¨è¾¾å†…å®¹
        4. ç½²åå»ºè®®ï¼šé€‚åˆçš„è½æ¬¾æ–¹å¼
        
        è¦æ±‚ï¼š
        - ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
        - æƒ…æ„ŸçœŸæŒšè‡ªç„¶
        - å­—æ•°é€‚ä¸­ï¼Œé€‚åˆæ˜ä¿¡ç‰‡å±•ç¤º
        
        ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚
        """
        
        content = await self.gemini_provider.generate_text(
            prompt=content_prompt,
            max_tokens=800,
            temperature=0.7
        )
        
        context["results"]["content"] = content
        return context
```

**4.3.2.3. å›¾ç‰‡ç”Ÿæˆå™¨ï¼ˆGeminiå›¾ç‰‡ç”Ÿæˆï¼‰**
```python
# src/ai-agent-service/app/orchestrator/steps/image_generator.py
from ..providers.gemini_image_provider import GeminiImageProvider
import json

class ImageGenerator:
    def __init__(self):
        self.gemini_image_provider = GeminiImageProvider()
    
    async def execute(self, context):
        """åŸºäºæ¦‚å¿µå’Œå†…å®¹ç”Ÿæˆæ˜ä¿¡ç‰‡é…å›¾"""
        task = context["task"]
        concept = context["results"]["concept"]
        content = context["results"]["content"]
        
        # è§£ææ¦‚å¿µä¸­çš„è§†è§‰é£æ ¼ä¿¡æ¯
        try:
            concept_data = json.loads(concept) if isinstance(concept, str) else concept
            visual_style = concept_data.get("è§†è§‰é£æ ¼", "")
        except:
            visual_style = "æ¸©é¦¨ã€ç®€æ´ã€ç°ä»£é£æ ¼"
        
        # æ„å»ºå›¾ç‰‡ç”Ÿæˆæç¤ºè¯
        image_prompt = f"""
        ä¸ºæ˜ä¿¡ç‰‡ç”Ÿæˆé…å›¾ï¼Œè¦æ±‚ï¼š
        
        è§†è§‰é£æ ¼ï¼š{visual_style}
        ä¸»é¢˜å†…å®¹ï¼š{task.user_input}
        
        æŠ€æœ¯è¦æ±‚ï¼š
        - é«˜è´¨é‡æ’ç”»é£æ ¼
        - è‰²å½©å’Œè°ï¼Œé€‚åˆæ˜ä¿¡ç‰‡ä½¿ç”¨
        - ç•™æœ‰æ–‡å­—æ‘†æ”¾ç©ºé—´
        - é¿å…è¿‡äºå¤æ‚çš„ç»†èŠ‚
        - æƒ…æ„Ÿè¡¨è¾¾ç§¯ææ­£é¢
        
        ç”»é¢æè¿°ï¼šè¯·åŸºäºä¸Šè¿°è¦æ±‚ç”Ÿæˆä¸€å¼ é€‚åˆæ˜ä¿¡ç‰‡çš„ç²¾ç¾æ’ç”»
        """
        
        # è°ƒç”¨Geminiå›¾ç‰‡ç”Ÿæˆ
        image_result = await self.gemini_image_provider.generate_image(
            prompt=image_prompt,
            size="1024x1024",
            quality="standard"
        )
        
        context["results"]["image_url"] = image_result["image_url"]
        context["results"]["image_metadata"] = image_result["metadata"]
        
        return context
```

**4.3.2.4. å‰ç«¯ä»£ç ç”Ÿæˆå™¨ï¼ˆClaude Code SDKï¼‰**
```python
# src/ai-agent-service/app/orchestrator/steps/frontend_coder.py
from ..coding_service.providers.claude_provider import ClaudeProvider
import json

class FrontendCoder:
    def __init__(self):
        self.claude_provider = ClaudeProvider()
    
    async def execute(self, context):
        """ç”Ÿæˆå‰ç«¯HTML/CSS/JSä»£ç """
        task = context["task"]
        concept = context["results"]["concept"]
        content = context["results"]["content"]
        image_url = context["results"]["image_url"]
        
        # è§£æå†…å®¹ç»“æ„
        try:
            content_data = json.loads(content) if isinstance(content, str) else content
        except:
            content_data = {"ä¸»æ ‡é¢˜": "ç”Ÿæˆå¤±è´¥", "æ­£æ–‡å†…å®¹": content}
        
        coding_prompt = f"""
        è¯·ç”Ÿæˆä¸€ä¸ªäº¤äº’å¼æ˜ä¿¡ç‰‡çš„å®Œæ•´å‰ç«¯ä»£ç ï¼Œè¦æ±‚ï¼š
        
        å†…å®¹ä¿¡æ¯ï¼š
        - ä¸»æ ‡é¢˜ï¼š{content_data.get('ä¸»æ ‡é¢˜', '')}
        - å‰¯æ ‡é¢˜ï¼š{content_data.get('å‰¯æ ‡é¢˜', '')}
        - æ­£æ–‡ï¼š{content_data.get('æ­£æ–‡å†…å®¹', '')}
        - èƒŒæ™¯å›¾ç‰‡ï¼š{image_url}
        
        æŠ€æœ¯è¦æ±‚ï¼š
        1. çº¯HTML/CSS/JSå®ç°
        2. é€‚é…ç§»åŠ¨ç«¯ï¼ˆå¾®ä¿¡å°ç¨‹åºwebviewï¼‰
        3. æ·»åŠ ç²¾ç¾çš„CSSåŠ¨ç”»æ•ˆæœ
        4. å®ç°äº¤äº’åŠŸèƒ½ï¼ˆç‚¹å‡»ã€æ»‘åŠ¨ç­‰ï¼‰
        5. å“åº”å¼è®¾è®¡ï¼Œé€‚åº”ä¸åŒå±å¹•å°ºå¯¸
        
        åŠ¨ç”»æ•ˆæœå»ºè®®ï¼š
        - æ–‡å­—æ¸ç°åŠ¨ç”»
        - èƒŒæ™¯å›¾ç‰‡ç¼“æ…¢ç¼©æ”¾
        - å¡ç‰‡ç¿»è½¬æˆ–æ¸å˜æ•ˆæœ
        - é¼ æ ‡æ‚¬åœäº’åŠ¨
        
        è¿”å›å®Œæ•´å¯è¿è¡Œçš„HTMLä»£ç ã€‚
        """
        
        # ä½¿ç”¨Claude Code SDKç”Ÿæˆå‰ç«¯ä»£ç 
        frontend_code = await self.claude_provider.generate_code(
            prompt=coding_prompt,
            language="html"
        )
        
        context["results"]["frontend_code"] = frontend_code
        context["results"]["preview_url"] = f"/preview/{task.task_id}"
        
        return context
```

### 4.4. Phase 4: APIé›†æˆå’Œæµ‹è¯•ï¼ˆ1å¤©ï¼‰

**4.4.1. APIç½‘å…³è·¯ç”±æ›´æ–°**
```python
# APIç½‘å…³æ–°å¢è·¯ç”±ï¼Œè½¬å‘åˆ°æ˜ä¿¡ç‰‡æœåŠ¡
@app.post("/api/v1/postcards/create")
async def create_postcard(request: PostcardRequest):
    # è½¬å‘åˆ°æ˜ä¿¡ç‰‡æœåŠ¡
    response = await postcard_service_client.create_task(request)
    return response

@app.get("/api/v1/postcards/status/{task_id}")  
async def get_postcard_status(task_id: str):
    # è½¬å‘åˆ°æ˜ä¿¡ç‰‡æœåŠ¡
    response = await postcard_service_client.get_task_status(task_id)
    return response
```

**4.4.2. å‰ç«¯é€‚é…**
```javascript
// å‰ç«¯éœ€è¦é€‚é…æ–°çš„å¼‚æ­¥æ¥å£
const createPostcard = async (prompt) => {
    // 1. åˆ›å»ºä»»åŠ¡
    const { task_id } = await fetch('/api/v1/postcards/create', {
        method: 'POST',
        body: JSON.stringify({ prompt })
    }).then(r => r.json())
    
    // 2. è½®è¯¢æˆ–WebSocketè·å–çŠ¶æ€
    const pollStatus = async () => {
        const status = await fetch(`/api/v1/postcards/status/${task_id}`)
            .then(r => r.json())
        
        if (status.status === 'COMPLETED') {
            displayResult(status.data)
        } else if (status.status === 'FAILED') {
            displayError(status.error)
        } else {
            setTimeout(pollStatus, 2000) // 2ç§’åé‡è¯•
        }
    }
    
    pollStatus()
}
```

## 5. é…ç½®å’Œç¯å¢ƒå˜é‡

### 5.1. æ–°å¢ç¯å¢ƒå˜é‡
```bash
# .env.example æ–°å¢
# Redisé…ç½®
REDIS_URL=redis://redis:6379
REDIS_PASSWORD=

# æ˜ä¿¡ç‰‡æœåŠ¡é…ç½®  
POSTCARD_SERVICE_URL=http://postcard-service:8000

# AIå·¥ä½œæµé…ç½®
AI_WORKFLOW_TIMEOUT=300  # 5åˆ†é’Ÿè¶…æ—¶
AI_WORKFLOW_RETRY_COUNT=3

# Gemini Provideré…ç½®ï¼ˆå·²åœ¨å‰é¢ç« èŠ‚æ·»åŠ ï¼‰
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_BASE_URL=https://generativelanguage.googleapis.com
GEMINI_TEXT_MODEL=gemini-1.5-flash
GEMINI_IMAGE_MODEL=imagen-3.0-generate-001
GEMINI_TEXT_MAX_TOKENS=2048
GEMINI_TEXT_TEMPERATURE=0.7
GEMINI_IMAGE_SIZE=1024x1024
GEMINI_IMAGE_QUALITY=standard
```

### 5.2. AI Agent æœåŠ¡è¯¦ç»†åŠŸèƒ½è®¾è®¡

#### 5.2.1. æ™ºèƒ½å·¥ä½œæµç¼–æ’

**å¤šProvideræ™ºèƒ½åˆ‡æ¢**ï¼š
```python
# src/ai-agent-service/app/orchestrator/smart_workflow.py
from enum import Enum
from typing import Dict, Any, List, Optional
from .workflow import PostcardWorkflow
from ..providers.provider_factory import ProviderFactory

class ProviderStrategy(Enum):
    """Provideré€‰æ‹©ç­–ç•¥"""
    COST_OPTIMIZED = "cost_optimized"      # æˆæœ¬ä¼˜åŒ–
    QUALITY_FIRST = "quality_first"        # è´¨é‡ä¼˜å…ˆ
    SPEED_FIRST = "speed_first"            # é€Ÿåº¦ä¼˜å…ˆ
    BALANCED = "balanced"                  # å¹³è¡¡æ¨¡å¼

class SmartWorkflow(PostcardWorkflow):
    """æ™ºèƒ½å·¥ä½œæµï¼Œæ”¯æŒåŠ¨æ€Provideré€‰æ‹©å’Œè‡ªé€‚åº”ä¼˜åŒ–"""
    
    def __init__(self, strategy: ProviderStrategy = ProviderStrategy.BALANCED):
        super().__init__()
        self.strategy = strategy
        self.performance_metrics = {}
        self.provider_health = {}
    
    async def execute_with_fallback(self, task, step_name: str, primary_provider: str, fallback_provider: str = None):
        """å¸¦é™çº§çš„æ­¥éª¤æ‰§è¡Œ"""
        try:
            # æ£€æŸ¥ä¸»Providerå¥åº·çŠ¶æ€
            if not await self.check_provider_health(primary_provider):
                if fallback_provider:
                    self.logger.warning(f"ä¸»Provider {primary_provider} ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ° {fallback_provider}")
                    return await self.execute_step_with_provider(task, step_name, fallback_provider)
                else:
                    raise Exception(f"Provider {primary_provider} ä¸å¯ç”¨ä¸”æ— å¤‡ç”¨Provider")
            
            # æ‰§è¡Œä¸»Provider
            return await self.execute_step_with_provider(task, step_name, primary_provider)
            
        except Exception as e:
            # è‡ªåŠ¨é™çº§
            if fallback_provider and primary_provider != fallback_provider:
                self.logger.warning(f"ä¸»Provideræ‰§è¡Œå¤±è´¥ï¼Œå°è¯•å¤‡ç”¨Provider: {e}")
                return await self.execute_step_with_provider(task, step_name, fallback_provider)
            else:
                raise
    
    async def adaptive_parameter_tuning(self, step_name: str, context: Dict) -> Dict:
        """è‡ªé€‚åº”å‚æ•°è°ƒä¼˜"""
        # åŸºäºå†å²æ€§èƒ½æ•°æ®è°ƒæ•´å‚æ•°
        historical_data = self.performance_metrics.get(step_name, {})
        
        if step_name == "text_generation":
            # æ–‡æœ¬ç”Ÿæˆå‚æ•°ä¼˜åŒ–
            if historical_data.get("avg_quality_score", 0) < 0.7:
                return {"temperature": 0.8, "max_tokens": 1500}  # æé«˜åˆ›é€ æ€§
            elif historical_data.get("avg_response_time", 0) > 30:
                return {"temperature": 0.6, "max_tokens": 1000}  # æé«˜é€Ÿåº¦
        
        return {}
```

#### 5.2.2. é«˜çº§é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

**æ™ºèƒ½é‡è¯•ç­–ç•¥**ï¼š
```python
# src/ai-agent-service/app/utils/retry_handler.py
import asyncio
import random
from typing import Callable, Any, Optional
from functools import wraps

class RetryConfig:
    """é‡è¯•é…ç½®"""
    def __init__(
        self,
        max_attempts: int = 3,
        base_delay: float = 1.0,
        max_delay: float = 60.0,
        exponential_base: float = 2.0,
        jitter: bool = True
    ):
        self.max_attempts = max_attempts
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.exponential_base = exponential_base
        self.jitter = jitter

class SmartRetryHandler:
    """æ™ºèƒ½é‡è¯•å¤„ç†å™¨"""
    
    @staticmethod
    def with_retry(config: RetryConfig):
        """é‡è¯•è£…é¥°å™¨"""
        def decorator(func: Callable):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                last_exception = None
                
                for attempt in range(config.max_attempts):
                    try:
                        return await func(*args, **kwargs)
                    except Exception as e:
                        last_exception = e
                        
                        # åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•
                        if not SmartRetryHandler.should_retry(e, attempt, config.max_attempts):
                            raise e
                        
                        # è®¡ç®—å»¶è¿Ÿæ—¶é—´
                        delay = SmartRetryHandler.calculate_delay(attempt, config)
                        
                        # è®°å½•é‡è¯•æ—¥å¿—
                        logger.warning(f"ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.2f}ç§’åé‡è¯•: {e}")
                        
                        await asyncio.sleep(delay)
                
                # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
                raise last_exception
            
            return wrapper
        return decorator
    
    @staticmethod
    def should_retry(exception: Exception, attempt: int, max_attempts: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        # ä¸é‡è¯•çš„é”™è¯¯ç±»å‹
        non_retryable_errors = [
            "InvalidAPIKey",
            "QuotaExceeded", 
            "ModelNotFound",
            "ValidationError"
        ]
        
        error_name = exception.__class__.__name__
        if error_name in non_retryable_errors:
            return False
        
        # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯
        error_msg = str(exception).lower()
        if any(keyword in error_msg for keyword in ["invalid api key", "quota exceeded", "model not found"]):
            return False
        
        return attempt < max_attempts - 1
    
    @staticmethod
    def calculate_delay(attempt: int, config: RetryConfig) -> float:
        """è®¡ç®—é‡è¯•å»¶è¿Ÿ"""
        delay = config.base_delay * (config.exponential_base ** attempt)
        delay = min(delay, config.max_delay)
        
        # æ·»åŠ æŠ–åŠ¨é¿å…é›·ç¾¤æ•ˆåº”
        if config.jitter:
            delay *= (0.5 + random.random() * 0.5)
        
        return delay
```

#### 5.2.3. æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜ç­–ç•¥

**å¤šçº§ç¼“å­˜ç³»ç»Ÿ**ï¼š
```python
# src/ai-agent-service/app/utils/cache_manager.py
import json
import hashlib
from typing import Any, Optional, Dict
import redis.asyncio as redis
from datetime import timedelta

class CacheManager:
    """å¤šçº§ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.redis_client = redis.Redis(host="redis", port=6379, decode_responses=True)
        self.memory_cache: Dict[str, Any] = {}
        self.cache_stats = {"hits": 0, "misses": 0}
    
    def generate_cache_key(self, prefix: str, data: Dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å’Œå“ˆå¸Œ
        normalized_data = json.dumps(data, sort_keys=True, ensure_ascii=False)
        hash_value = hashlib.md5(normalized_data.encode()).hexdigest()
        return f"{prefix}:{hash_value}"
    
    async def get_cached_result(self, cache_key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜ç»“æœ"""
        # 1. å°è¯•å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            self.cache_stats["hits"] += 1
            return self.memory_cache[cache_key]
        
        # 2. å°è¯•Redisç¼“å­˜
        cached_data = await self.redis_client.get(cache_key)
        if cached_data:
            try:
                result = json.loads(cached_data)
                # åŒæ­¥åˆ°å†…å­˜ç¼“å­˜
                self.memory_cache[cache_key] = result
                self.cache_stats["hits"] += 1
                return result
            except json.JSONDecodeError:
                pass
        
        self.cache_stats["misses"] += 1
        return None
    
    async def cache_result(self, cache_key: str, result: Any, ttl: int = 3600):
        """ç¼“å­˜ç»“æœ"""
        try:
            # å­˜å‚¨åˆ°å†…å­˜ç¼“å­˜
            self.memory_cache[cache_key] = result
            
            # å­˜å‚¨åˆ°Redisï¼ˆå¸¦è¿‡æœŸæ—¶é—´ï¼‰
            cached_data = json.dumps(result, ensure_ascii=False)
            await self.redis_client.setex(cache_key, ttl, cached_data)
            
        except Exception as e:
            logger.error(f"ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.cache_stats["hits"] + self.cache_stats["misses"]
        hit_rate = self.cache_stats["hits"] / total_requests if total_requests > 0 else 0
        
        return {
            "hit_rate": hit_rate,
            "total_hits": self.cache_stats["hits"],
            "total_misses": self.cache_stats["misses"],
            "memory_cache_size": len(self.memory_cache)
        }

# ä½¿ç”¨ç¤ºä¾‹
class CachedConceptGenerator:
    """å¸¦ç¼“å­˜çš„æ¦‚å¿µç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.cache_manager = CacheManager()
        self.provider = GeminiTextProvider()
    
    async def generate_concept(self, user_input: str, style: str = None) -> str:
        # æ„å»ºç¼“å­˜é”®
        cache_data = {"user_input": user_input, "style": style, "step": "concept"}
        cache_key = self.cache_manager.generate_cache_key("concept_gen", cache_data)
        
        # å°è¯•è·å–ç¼“å­˜
        cached_result = await self.cache_manager.get_cached_result(cache_key)
        if cached_result:
            return cached_result
        
        # ç”Ÿæˆæ–°å†…å®¹
        concept = await self.provider.generate_text(f"ç”Ÿæˆæ¦‚å¿µï¼š{user_input}ï¼Œé£æ ¼ï¼š{style}")
        
        # ç¼“å­˜ç»“æœï¼ˆæ¦‚å¿µç¼“å­˜1å°æ—¶ï¼‰
        await self.cache_manager.cache_result(cache_key, concept, ttl=3600)
        
        return concept
```

#### 5.2.4. å®æ—¶ç›‘æ§å’Œæ€§èƒ½åˆ†æ

**æ€§èƒ½ç›‘æ§ç³»ç»Ÿ**ï¼š
```python
# src/ai-agent-service/app/utils/performance_monitor.py
import time
import asyncio
from typing import Dict, List, Any
from collections import defaultdict, deque
from datetime import datetime, timedelta

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, window_size: int = 100):
        self.metrics = defaultdict(lambda: deque(maxlen=window_size))
        self.counters = defaultdict(int)
        self.start_time = time.time()
    
    async def track_operation(self, operation_name: str, func, *args, **kwargs):
        """è·Ÿè¸ªæ“ä½œæ€§èƒ½"""
        start_time = time.time()
        success = False
        error_msg = None
        
        try:
            result = await func(*args, **kwargs)
            success = True
            return result
        except Exception as e:
            error_msg = str(e)
            raise
        finally:
            duration = time.time() - start_time
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            self.record_metric(operation_name, {
                "duration": duration,
                "success": success,
                "error": error_msg,
                "timestamp": datetime.now()
            })
    
    def record_metric(self, metric_name: str, data: Dict[str, Any]):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        self.metrics[metric_name].append(data)
        
        # æ›´æ–°è®¡æ•°å™¨
        if data.get("success"):
            self.counters[f"{metric_name}_success"] += 1
        else:
            self.counters[f"{metric_name}_error"] += 1
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        summary = {}
        
        for metric_name, records in self.metrics.items():
            if not records:
                continue
            
            durations = [r["duration"] for r in records if r.get("duration")]
            success_count = sum(1 for r in records if r.get("success"))
            total_count = len(records)
            
            summary[metric_name] = {
                "avg_duration": sum(durations) / len(durations) if durations else 0,
                "min_duration": min(durations) if durations else 0,
                "max_duration": max(durations) if durations else 0,
                "success_rate": success_count / total_count if total_count > 0 else 0,
                "total_requests": total_count,
                "recent_errors": [r["error"] for r in list(records)[-5:] if r.get("error")]
            }
        
        summary["uptime_seconds"] = time.time() - self.start_time
        return summary
    
    def get_health_score(self) -> float:
        """è®¡ç®—ç³»ç»Ÿå¥åº·åˆ†æ•° (0-1)"""
        summary = self.get_performance_summary()
        
        if not summary:
            return 1.0  # æ— æ•°æ®æ—¶è®¤ä¸ºå¥åº·
        
        total_score = 0
        weight_sum = 0
        
        for metric_name, stats in summary.items():
            if metric_name == "uptime_seconds":
                continue
            
            # æˆåŠŸç‡æƒé‡ (0.6)
            success_rate = stats.get("success_rate", 1.0)
            total_score += success_rate * 0.6
            weight_sum += 0.6
            
            # å“åº”æ—¶é—´æƒé‡ (0.4)
            avg_duration = stats.get("avg_duration", 0)
            if avg_duration > 0:
                # å‡è®¾ç†æƒ³å“åº”æ—¶é—´ä¸º5ç§’
                time_score = max(0, 1 - (avg_duration - 5) / 30)  # 30ç§’ä»¥ä¸Šä¸º0åˆ†
                total_score += time_score * 0.4
                weight_sum += 0.4
        
        return total_score / weight_sum if weight_sum > 0 else 1.0
```

### 5.2. Docker Composeæ›´æ–°
```yaml
# docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      
  postcard-service:
    build:
      context: ./src/postcard-service
      dockerfile: Dockerfile.dev
    ports:
      - "8003:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    profiles: ["postcard", "all"]
      
  ai-agent-service:
    # ç°æœ‰é…ç½®åŸºç¡€ä¸Šæ·»åŠ 
    environment:
      - REDIS_URL=redis://redis:6379
      - POSTCARD_SERVICE_URL=http://postcard-service:8000
    depends_on:
      - redis
      - postcard-service
```

## 6. å¼€å‘å’Œæµ‹è¯•æŒ‡ä»¤

### 6.1. å¼€å‘ç¯å¢ƒå¯åŠ¨
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆåŒ…æ‹¬æ–°çš„Rediså’Œæ˜ä¿¡ç‰‡æœåŠ¡ï¼‰
sh scripts/dev.sh up all

# ä»…å¯åŠ¨ç›¸å…³æœåŠ¡è¿›è¡Œå¼€å‘
sh scripts/dev.sh up redis postcard ai-agent

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
sh scripts/dev.sh ps
sh scripts/dev.sh logs ai-agent-service
```

### 6.2. æµ‹è¯•å‘½ä»¤
```bash
# æµ‹è¯•Redisè¿æ¥
sh scripts/dev.sh exec ai-agent-service python -c "import redis; r=redis.Redis(host='redis'); print(r.ping())"

# æµ‹è¯•ä»»åŠ¡æ¶ˆè´¹è€…
sh scripts/dev.sh exec ai-agent-service python app/worker.py

# æµ‹è¯•å®Œæ•´å·¥ä½œæµ
sh scripts/dev.sh exec ai-agent-service pytest tests/test_workflow.py -v

# é›†æˆæµ‹è¯•
curl -X POST http://localhost:8001/api/v1/postcards/create \
  -H "Content-Type: application/json" \
  -d '{"prompt": "åˆ›å»ºä¸€ä¸ªç”Ÿæ—¥ç¥ç¦æ˜ä¿¡ç‰‡ï¼Œæ¸©é¦¨å¯çˆ±é£æ ¼"}'
```

## 7. æ•°æ®åº“Schemaæ›´æ–°

### 7.1. æ˜ä¿¡ç‰‡è¡¨
```sql
-- src/postcard-service/database/migrations/001_initial.sql
CREATE TABLE postcards (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    task_id VARCHAR(255) UNIQUE NOT NULL,
    user_id UUID REFERENCES users(id),
    status VARCHAR(50) NOT NULL DEFAULT 'pending',
    user_input TEXT NOT NULL,
    style VARCHAR(100),
    theme VARCHAR(100),
    
    -- AIç”Ÿæˆçš„ä¸­é—´ç»“æœ
    concept TEXT,
    content TEXT,
    image_url VARCHAR(500),
    
    -- æœ€ç»ˆç»“æœ
    frontend_code TEXT,
    preview_url VARCHAR(500),
    
    -- å…ƒæ•°æ®
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP,
    
    -- é”™è¯¯ä¿¡æ¯
    error_message TEXT,
    retry_count INTEGER DEFAULT 0
);

CREATE INDEX idx_postcards_task_id ON postcards(task_id);
CREATE INDEX idx_postcards_user_id ON postcards(user_id);
CREATE INDEX idx_postcards_status ON postcards(status);
```

## 8. ç›‘æ§å’Œæ—¥å¿—

### 8.1. å…³é”®æŒ‡æ ‡ç›‘æ§
- ä»»åŠ¡å¤„ç†æ—¶é—´åˆ†å¸ƒ
- å„æ­¥éª¤æˆåŠŸç‡
- é˜Ÿåˆ—å †ç§¯æƒ…å†µ
- èµ„æºä½¿ç”¨ç‡

### 8.2. æ—¥å¿—è§„èŒƒ
```python
# ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼
logger.info("ä»»åŠ¡å¼€å§‹å¤„ç†", extra={
    "task_id": task.task_id,
    "step": "concept_generation",
    "user_input_length": len(task.user_input)
})
```

## 9. éªŒæ”¶æ ‡å‡†

### 9.1. åŠŸèƒ½éªŒæ”¶
- [ ] ç”¨æˆ·åˆ›å»ºæ˜ä¿¡ç‰‡ä»»åŠ¡ï¼Œç«‹å³è¿”å›task_id
- [ ] ä»»åŠ¡è¿›å…¥æ¶ˆæ¯é˜Ÿåˆ—ï¼ŒAI Agentè‡ªåŠ¨æ¶ˆè´¹  
- [ ] å®Œæ•´æ‰§è¡Œ4æ­¥éª¤å·¥ä½œæµï¼šæ¦‚å¿µâ†’æ–‡æ¡ˆâ†’å›¾ç‰‡â†’ä»£ç 
- [ ] å„æ­¥éª¤ç»“æœæ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“
- [ ] å‰ç«¯å¯ä»¥æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œæœ€ç»ˆç»“æœ
- [ ] é”™è¯¯æƒ…å†µä¸‹ä»»åŠ¡çŠ¶æ€æ­£ç¡®æ›´æ–°

### 9.2. æ€§èƒ½éªŒæ”¶  
- [ ] å•ä»»åŠ¡å¤„ç†æ—¶é—´ < 2åˆ†é’Ÿ
- [ ] æ”¯æŒå¹¶å‘å¤„ç†å¤šä¸ªä»»åŠ¡
- [ ] ç³»ç»Ÿèµ„æºå ç”¨åˆç†
- [ ] ä»»åŠ¡å¤±è´¥æœ‰é‡è¯•æœºåˆ¶

### 9.3. ç¨³å®šæ€§éªŒæ”¶
- [ ] æœåŠ¡é‡å¯åä»»åŠ¡èƒ½æ¢å¤å¤„ç†
- [ ] Redisè¿æ¥æ–­å¼€èƒ½è‡ªåŠ¨é‡è¿
- [ ] å„æœåŠ¡é—´ä¾èµ–å¥åº·æ£€æŸ¥

## 10. é£é™©å’Œåº”å¯¹

### 10.1. æŠ€æœ¯é£é™©
**é£é™©**: Claude Code SDKåœ¨å¤šæ­¥éª¤å·¥ä½œæµä¸­çš„å…¼å®¹æ€§  
**åº”å¯¹**: å…ˆå®ç°æœ€å°å¯è¡Œæ–¹æ¡ˆï¼Œé€æ­¥å®Œå–„å„æ­¥éª¤

**é£é™©**: Redisæ¶ˆæ¯é˜Ÿåˆ—å¯é æ€§  
**åº”å¯¹**: å®ç°æ¶ˆæ¯ç¡®è®¤æœºåˆ¶å’Œé‡è¯•é€»è¾‘

### 10.2. å¼€å‘é£é™©
**é£é™©**: å¼€å‘æ—¶é—´ä¼°ç®—ä¸å‡†ç¡®  
**åº”å¯¹**: æŒ‰Phaseåˆ†é˜¶æ®µäº¤ä»˜ï¼Œä¼˜å…ˆä¿è¯æ ¸å¿ƒæµç¨‹

**é£é™©**: æœåŠ¡é—´é›†æˆå¤æ‚åº¦  
**åº”å¯¹**: å……åˆ†çš„é›†æˆæµ‹è¯•å’Œæ–‡æ¡£

---

**å¼€å‘å‡†å¤‡å°±ç»ªchecklist**:
- [ ] ç¯å¢ƒå˜é‡é…ç½®å®Œæˆ
- [ ] Dockerç¯å¢ƒæ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸  
- [ ] å¼€å‘åˆ†æ”¯åˆ›å»º
- [ ] å›¢é˜Ÿæ²Ÿé€šåè°ƒ

**é¢„è®¡å®Œæˆæ—¶é—´**: 2024-08-25
**è´Ÿè´£äºº**: AIæ¶æ„å¸ˆ
**Review**: é¡¹ç›®è´Ÿè´£äºº